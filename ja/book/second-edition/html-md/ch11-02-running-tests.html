<!DOCTYPE html>
<h2>Controlling How Tests Are Run</h2>
<br>
<p>Just as <code>cargo run</code> compiles your code and then runs the resulting binary,
<code>cargo test</code> compiles your code in test mode and runs the resulting test
binary. You can specify command line options to change the default behavior of
<code>cargo test</code>. For example, the default behavior of the binary produced by
<code>cargo test</code> is to run all the tests in parallel and capture output generated
during test runs, preventing the output from being displayed and making it
easier to read the output related to the test results.</p>
<br>
<p>Some command line options go to <code>cargo test</code>, and some go to the resulting test
binary. To separate these two types of arguments, you list the arguments that
go to <code>cargo test</code> followed by the separator <code>--</code> and then the ones that go to
the test binary. Running <code>cargo test --help</code> displays the options you can use
with <code>cargo test</code>, and running <code>cargo test -- --help</code> displays the options you
can use after the separator <code>--</code>.</p>
<br>
<h3>Running Tests in Parallel or Consecutively</h3>
<br>
<p>When you run multiple tests, by default they run in parallel using threads.
This means the tests will finish running faster so you can get feedback quicker
on whether or not your code is working. Because the tests are running at the
same time, make sure your tests don’t depend on each other or on any shared
state, including a shared environment, such as the current working directory or
environment variables.</p>
<br>
<p>For example, say each of your tests runs some code that creates a file on disk
named <i>test-output.txt</i> and writes some data to that file. Then each test reads
the data in that file and asserts that the file contains a particular value,
which is different in each test. Because the tests run at the same time, one
test might overwrite the file between when another test writes and reads the
file. The second test will then fail, not because the code is incorrect but
because the tests have interfered with each other while running in parallel.
One solution is to make sure each test writes to a different file; another
solution is to run the tests one at a time.</p>
<br>
<p>If you don’t want to run the tests in parallel or if you want more fine-grained
control over the number of threads used, you can send the <code>--test-threads</code> flag
and the number of threads you want to use to the test binary. Take a look at
the following example:</p>
<br>
<div data-lang="text"><div data-l="$ cargo test -- --test-threads=1"></div></div>
<br>
<p>We set the number of test threads to <code>1</code>, telling the program not to use any
parallelism. Running the tests using one thread will take longer than running
them in parallel, but the tests won’t interfere with each other if they share
state.</p>
<br>
<h3>Showing Function Output</h3>
<br>
<p>By default, if a test passes, Rust’s test library captures anything printed to
standard output. For example, if we call <code>println€</code> in a test and the test
passes, we won’t see the <code>println€</code> output in the terminal; we’ll see only the
line that indicates the test passed. If a test fails, we’ll see whatever was
printed to standard output with the rest of the failure message.</p>
<br>
<p>As an example, Listing 11-10 has a silly function that prints the value of its
parameter and returns 10, as well as a test that passes and a test that fails.</p>
<br>
<p><span class="filename">Filename: src/lib.rs</span></p>
<br>
<div data-lang="rust"><div data-l="fn prints_and_returns_10(a: i32) -&gt; i32 {"></div><div data-l="    println!(&quot;I got the value {}&quot;, a);"></div><div data-l="    10"></div><div data-l="}"></div><div data-l=""></div><div data-l="#[cfg(test)]"></div><div data-l="mod tests {"></div><div data-l="    use super::*;"></div><div data-l=""></div><div data-l="    #[test]"></div><div data-l="    fn this_test_will_pass() {"></div><div data-l="        let value = prints_and_returns_10(4);"></div><div data-l="        assert_eq!(10, value);"></div><div data-l="    }"></div><div data-l=""></div><div data-l="    #[test]"></div><div data-l="    fn this_test_will_fail() {"></div><div data-l="        let value = prints_and_returns_10(8);"></div><div data-l="        assert_eq!(5, value);"></div><div data-l="    }"></div><div data-l="}"></div></div>
<br>
<p><span class="caption">Listing 11-10: Tests for a function that calls
<code>println€</code></span></p>
<br>
<p>When we run these tests with <code>cargo test</code>, we’ll see the following output:</p>
<br>
<div data-lang="text"><div data-l="running 2 tests"></div><div data-l="test tests::this_test_will_pass ... ok"></div><div data-l="test tests::this_test_will_fail ... FAILED"></div><div data-l=""></div><div data-l="failures:"></div><div data-l=""></div><div data-l="---- tests::this_test_will_fail stdout ----"></div><div data-l="        I got the value 8"></div><div data-l="thread 'tests::this_test_will_fail' panicked at 'assertion failed: `(left == right)`"></div><div data-l="  left: `5`,"></div><div data-l=" right: `10`', src/lib.rs:19:8"></div><div data-l="note: Run with `RUST_BACKTRACE=1` for a backtrace."></div><div data-l=""></div><div data-l="failures:"></div><div data-l="    tests::this_test_will_fail"></div><div data-l=""></div><div data-l="test result: FAILED. 1 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out"></div></div>
<br>
<p>Note that nowhere in this output do we see <code>I got the value 4</code>, which is what
is printed when the test that passes runs. That output has been captured. The
output from the test that failed, <code>I got the value 8</code>, appears in the section
of the test summary output, which also shows the cause of the test failure.</p>
<br>
<p>If we want to see printed values for passing tests as well, we can disable the
output capture behavior by using the <code>--nocapture</code> flag:</p>
<br>
<div data-lang="text"><div data-l="$ cargo test -- --nocapture"></div></div>
<br>
<p>When we run the tests in Listing 11-10 again with the <code>--nocapture</code> flag, we
see the following output:</p>
<br>
<div data-lang="text"><div data-l="running 2 tests"></div><div data-l="I got the value 4"></div><div data-l="I got the value 8"></div><div data-l="test tests::this_test_will_pass ... ok"></div><div data-l="thread 'tests::this_test_will_fail' panicked at 'assertion failed: `(left == right)`"></div><div data-l="  left: `5`,"></div><div data-l=" right: `10`', src/lib.rs:19:8"></div><div data-l="note: Run with `RUST_BACKTRACE=1` for a backtrace."></div><div data-l="test tests::this_test_will_fail ... FAILED"></div><div data-l=""></div><div data-l="failures:"></div><div data-l=""></div><div data-l="failures:"></div><div data-l="    tests::this_test_will_fail"></div><div data-l=""></div><div data-l="test result: FAILED. 1 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out"></div></div>
<br>
<p>Note that the output for the tests and the test results are interleaved; the
reason is that the tests are running in parallel, as we talked about in the
previous section. Try using the <code>--test-threads=1</code> option and the <code>--nocapture</code>
flag, and see what the output looks like then!</p>
<br>
<h3>Running a Subset of Tests by Name</h3>
<br>
<p>Sometimes, running a full test suite can take a long time. If you’re working on
code in a particular area, you might want to run only the tests pertaining to
that code. You can choose which tests to run by passing <code>cargo test</code> the name
or names of the test(s) you want to run as an argument.</p>
<br>
<p>To demonstrate how to run a subset of tests, we’ll create three tests for our
<code>add_two</code> function, as shown in Listing 11-11, and choose which ones to run.</p>
<br>
<p><span class="filename">Filename: src/lib.rs</span></p>
<br>
<div data-lang="rust"><div data-l="pub fn add_two(a: i32) -&gt; i32 {"></div><div data-l="    a + 2"></div><div data-l="}"></div><div data-l=""></div><div data-l="#[cfg(test)]"></div><div data-l="mod tests {"></div><div data-l="    use super::*;"></div><div data-l=""></div><div data-l="    #[test]"></div><div data-l="    fn add_two_and_two() {"></div><div data-l="        assert_eq!(4, add_two(2));"></div><div data-l="    }"></div><div data-l=""></div><div data-l="    #[test]"></div><div data-l="    fn add_three_and_two() {"></div><div data-l="        assert_eq!(5, add_two(3));"></div><div data-l="    }"></div><div data-l=""></div><div data-l="    #[test]"></div><div data-l="    fn one_hundred() {"></div><div data-l="        assert_eq!(102, add_two(100));"></div><div data-l="    }"></div><div data-l="}"></div></div>
<br>
<p><span class="caption">Listing 11-11: Three tests with three different
names</span></p>
<br>
<p>If we run the tests without passing any arguments, as we saw earlier, all the
tests will run in parallel:</p>
<br>
<div data-lang="text"><div data-l="running 3 tests"></div><div data-l="test tests::add_two_and_two ... ok"></div><div data-l="test tests::add_three_and_two ... ok"></div><div data-l="test tests::one_hundred ... ok"></div><div data-l=""></div><div data-l="test result: ok. 3 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out"></div></div>
<br>
<h4>Running Single Tests</h4>
<br>
<p>We can pass the name of any test function to <code>cargo test</code> to run only that test:</p>
<br>
<div data-lang="text"><div data-l="$ cargo test one_hundred"></div><div data-l="    Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs"></div><div data-l="     Running target/debug/deps/adder-06a75b4a1f2515e9"></div><div data-l=""></div><div data-l="running 1 test"></div><div data-l="test tests::one_hundred ... ok"></div><div data-l=""></div><div data-l="test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 2 filtered out"></div></div>
<br>
<p>Only the test with the name <code>one_hundred</code> ran; the other two tests didn’t match
that name. The test output lets us know we had more tests than what this
command ran by displaying <code>2 filtered out</code> at the end of the summary line.</p>
<br>
<p>We can’t specify the names of multiple tests in this way; only the first value
given to <code>cargo test</code> will be used. But there is a way to run multiple tests.</p>
<br>
<h4>Filtering to Run Multiple Tests</h4>
<br>
<p>We can specify part of a test name, and any test whose name matches that value
will be run. For example, because two of our tests’ names contain <code>add</code>, we can
run those two by running <code>cargo test add</code>:</p>
<br>
<div data-lang="text"><div data-l="$ cargo test add"></div><div data-l="    Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs"></div><div data-l="     Running target/debug/deps/adder-06a75b4a1f2515e9"></div><div data-l=""></div><div data-l="running 2 tests"></div><div data-l="test tests::add_two_and_two ... ok"></div><div data-l="test tests::add_three_and_two ... ok"></div><div data-l=""></div><div data-l="test result: ok. 2 passed; 0 failed; 0 ignored; 0 measured; 1 filtered out"></div></div>
<br>
<p>This command ran all tests with <code>add</code> in the name and filtered out the test
named <code>one_hundred</code>. Also note that the module in which tests appear becomes
part of the test’s name, so we can run all the tests in a module by filtering
on the module’s name.</p>
<br>
<h3>Ignoring Some Tests Unless Specifically Requested</h3>
<br>
<p>Sometimes a few specific tests can be very time-consuming to execute, so you
might want to exclude them during most runs of <code>cargo test</code>. Rather than
listing as arguments all tests you do want to run, you can instead annotate the
time-consuming tests using the <code>ignore</code> attribute to exclude them, as shown
here:</p>
<br>
<p><span class="filename">Filename: src/lib.rs</span></p>
<br>
<div data-lang="rust"><div data-l="#[test]"></div><div data-l="fn it_works() {"></div><div data-l="    assert_eq!(2 + 2, 4);"></div><div data-l="}"></div><div data-l=""></div><div data-l="#[test]"></div><div data-l="#[ignore]"></div><div data-l="fn expensive_test() {"></div><div data-l="#    // code that takes an hour to run"></div><div data-l="    // ">code that takes an hour to run</div><div data-l="}"></div></div>
<br>
<p>After <code>#[test]</code> we add the <code>#[ignore]</code> line to the test we want to exclude. Now
when we run our tests, <code>it_works</code> runs, but <code>expensive_test</code> doesn’t:</p>
<br>
<div data-lang="text"><div data-l="$ cargo test"></div><div data-l="   Compiling adder v0.1.0 (file:///projects/adder)"></div><div data-l="    Finished dev [unoptimized + debuginfo] target(s) in 0.24 secs"></div><div data-l="     Running target/debug/deps/adder-ce99bcc2479f4607"></div><div data-l=""></div><div data-l="running 2 tests"></div><div data-l="test expensive_test ... ignored"></div><div data-l="test it_works ... ok"></div><div data-l=""></div><div data-l="test result: ok. 1 passed; 0 failed; 1 ignored; 0 measured; 0 filtered out"></div></div>
<br>
<p>The <code>expensive_test</code> function is listed as <code>ignored</code>. If we want to run only
the ignored tests, we can use <code>cargo test -- --ignored</code>:</p>
<br>
<div data-lang="text"><div data-l="$ cargo test -- --ignored"></div><div data-l="    Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs"></div><div data-l="     Running target/debug/deps/adder-ce99bcc2479f4607"></div><div data-l=""></div><div data-l="running 1 test"></div><div data-l="test expensive_test ... ok"></div><div data-l=""></div><div data-l="test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 1 filtered out"></div></div>
<br>
<p>By controlling which tests run, you can make sure your <code>cargo test</code> results
will be fast. When you’re at a point where it makes sense to check the results
of the <code>ignored</code> tests and you have time to wait for the results, you can run
<code>cargo test -- --ignored</code> instead.</p>